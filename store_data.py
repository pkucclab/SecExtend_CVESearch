import json
import os
from meilisearch import Client
from meilisearch.errors import MeilisearchApiError
from tqdm import tqdm  


def load_cve_data(file_path):
    """åŠ è½½æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡çš„æ–‡ä»¶"""
    data = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:  # è·³è¿‡ç©ºè¡Œ
                    try:
                        item = json.loads(line)
                        data.append(item)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ è¡Œè§£æå¤±è´¥: {line[:50]}... | é”™è¯¯: {str(e)}")
        return data
    except Exception as e:
        print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {file_path} | é”™è¯¯: {str(e)}")
        return []

def setup_meilisearch_index(client, index_name="cve"):
    """é…ç½® Meilisearch ç´¢å¼•ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    try:
        # 1. åˆ›å»ºç´¢å¼•ï¼ˆå¼‚æ­¥ä»»åŠ¡ï¼‰
        task = client.create_index(uid=index_name, options={'primaryKey': 'cve_id'})
        
        # 2. ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆå…³é”®æ­¥éª¤ï¼ï¼‰
        client.wait_for_task(task.task_uid)
        
        # 3. è·å–çœŸæ­£çš„ç´¢å¼•å¯¹è±¡
        index = client.get_index(index_name)
        
        # 4. é…ç½®æœç´¢å±æ€§
        index.update_searchable_attributes([
            "cve_id", "description", "cve_mapping.explaination",
            "cve_mapping.vulnerability_type.type", "related_attcks.name"
        ])
        
        # 5. é…ç½®ç­›é€‰å±æ€§
        index.update_filterable_attributes([
            "cvss_severity", "year", "cvss_base_score",
            "cve_mapping.vulnerability_type.type"
        ])
        
        print(f"âœ… ç´¢å¼• {index_name} é…ç½®å®Œæˆ")
        return index
    except MeilisearchApiError as e:
        print(f"âŒ ç´¢å¼•é…ç½®å¤±è´¥: {e.message}")
        return None

def import_to_meilisearch(index, data, batch_size=500):
    """ä¿®å¤ç‰ˆæ•°æ®å¯¼å…¥å‡½æ•°"""
    try:
        total = len(data)
        for i in tqdm(range(0, total, batch_size), desc="å¯¼å…¥è¿›åº¦"):
            batch = data[i:i + batch_size]
            # æäº¤æ–‡æ¡£å¹¶è·å–ä»»åŠ¡å¯¹è±¡
            task = index.add_documents(batch)
            
            # âœ… å…³é”®ä¿®å¤ï¼šç­‰å¾…ä»»åŠ¡å®Œæˆå¹¶æ£€æŸ¥çŠ¶æ€ [1](@ref)
            task_status = index.wait_for_task(task.task_uid)
            if task_status.status != "succeeded":
                print(f"âš ï¸ æ‰¹æ¬¡ {i//batch_size} æäº¤å¤±è´¥: {task_status.error}")
                
        print(f"ğŸ‰ æˆåŠŸå¯¼å…¥ {total} æ¡è®°å½•")
    except Exception as e:
        print(f"âŒ æ•°æ®å¯¼å…¥å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    # é…ç½® Meilisearch å®¢æˆ·ç«¯
    MEILI_URL = "http://localhost:7700"
    MEILI_API_KEY = "pkucc_crimosn_data"  
    
    client = Client(MEILI_URL, MEILI_API_KEY)
    
    # åŠ è½½æ•°æ®æ–‡ä»¶
    DATA_DIR = "/home/zyx/crimson_data/data/json_files"  # æ›¿æ¢ä¸ºä½ çš„æ•°æ®ç›®å½•
    train_data = load_cve_data(os.path.join(DATA_DIR, "train.json"))
    test_data = load_cve_data(os.path.join(DATA_DIR, "test.json"))
    
    if not train_data and not test_data:
        print("ğŸš« æœªåŠ è½½åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè„šæœ¬ç»ˆæ­¢")
        exit(1)
    
    # é…ç½®ç´¢å¼•
    index = setup_meilisearch_index(client)
    if not index:
        exit(1)
    
    # å¯¼å…¥æ•°æ®
    if train_data:
        print(f"\nğŸ“¥ å¼€å§‹å¯¼å…¥è®­ç»ƒæ•°æ® ({len(train_data)} æ¡)")
        import_to_meilisearch(index, train_data)
    
    if test_data:
        print(f"\nğŸ“¥ å¼€å§‹å¯¼å…¥æµ‹è¯•æ•°æ® ({len(test_data)} æ¡)")
        import_to_meilisearch(index, test_data)
    
    # éªŒè¯ç»“æœ
    try:
        stats = index.get_stats()
        print("\nğŸ” å¯¼å…¥ç»“æœç»Ÿè®¡:")
        # âœ… ä½¿ç”¨å±æ€§è®¿é—®è€Œéä¸‹æ ‡ [6,7](@ref)
        print(f"â€¢ æ€»è®°å½•æ•°: {stats.number_of_documents}")
    except MeilisearchApiError as e:
        print(f"âŒ ç»Ÿè®¡è·å–å¤±è´¥: {e.message}")